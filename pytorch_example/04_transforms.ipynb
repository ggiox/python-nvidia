{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformações\n",
    "==========\n",
    "\n",
    "Os dados nem sempre chegam em sua forma final processada, necessária para o \n",
    "treinamento de algoritmos de aprendizado de máquina. \n",
    "Usamos **transformações** para realizar alguma manipulação dos dados e torná-los adequados para treinamento.\n",
    "\n",
    "Todos os conjuntos de dados do TorchVision têm dois parâmetros -`transform` \n",
    "para modificar os recursos e `target_transform` para modificar os rótulos — que \n",
    "aceitam chamadas contendo a lógica de transformação. O módulo. O módulo \n",
    "[torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)\n",
    "oferece diversas transformações comuns prontas para uso..\n",
    "\n",
    "Os recursos do FashionMNIST estão no formato de imagem PIL e os rótulos são inteiros. \n",
    "Para o treinamento, precisamos dos recursos como tensores normalizados e \n",
    "dos rótulos como tensores codificados em um único ponto. \n",
    "Para fazer essas transformações, usamos `ToTensor` e `Lambda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToTensor()\n",
    "==========\n",
    "\n",
    "O [ToTensor](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor)\n",
    "converte uma imagem PIL ou NumPy `ndarray` em um `FloatTensor`. \n",
    "e dimensiona os valores de intensidade de pixels da imagem no intervalo [0., 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformações Lambda\n",
    "=================\n",
    "\n",
    "As transformações lambda aplicam qualquer função lambda definida pelo usuário. \n",
    "Aqui, definimos uma função para transformar o inteiro em um tensor codificado em um ponto quente. \n",
    "Primeiro, ela cria um tensor zero de tamanho 10 (o número de rótulos em nosso conjunto de dados) e chama\n",
    "[scatter\\_](https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html)\n",
    "que atribui um valor `value=1` no índice fornecido pelo rótulo `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_transform = Lambda(lambda y: torch.zeros(\n",
    "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura adicional\n",
    "===============\n",
    "\n",
    "-   [torchvision.transforms\n",
    "    API](https://pytorch.org/vision/stable/transforms.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
