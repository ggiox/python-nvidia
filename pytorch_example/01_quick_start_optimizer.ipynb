{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Início rápido\n",
    "==========\n",
    "\n",
    "Esta seção aborda a API para tarefas comuns em aprendizado de máquina.  \n",
    "Consulte os links em cada seção para se aprofundar.\n",
    "\n",
    "Trabalhando com dados\n",
    "-----------------\n",
    "\n",
    "O PyTorch tem dois [primitivos para trabalhar com dados](https://pytorch.org/docs/stable/data.html):\n",
    "`torch.utils.data.DataLoader` e `torch.utils.data.Dataset`.  \n",
    "`Dataset` armazena as amostras e seus rótulos correspondentes e `DataLoader` envolve um iterável em torno do `Dataset`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Version: 2.9.0+cu126\n",
      "Device: NVIDIA GeForce GTX 1060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "print(f\"Pytorch Version: {torch.__version__}\") \n",
    "print(f\"Device: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O PyTorch oferece bibliotecas específicas de domínio, como\n",
    "[TorchText](https://pytorch.org/text/stable/index.html),\n",
    "[TorchVision](https://pytorch.org/vision/stable/index.html), and\n",
    "[TorchAudio](https://pytorch.org/audio/stable/index.html), \n",
    "todas elas incluindo conjuntos de dados. \n",
    "Neste tutorial, usaremos um conjunto de dados TorchVision.\n",
    "\n",
    "O módulo `torchvision.datasets` contém `Dataset` objetos para diversos dados de visão do mundo real, como CIFAR e COCO\n",
    "([lista completa aqui](https://pytorch.org/vision/stable/datasets.html)). \n",
    "Neste tutorial, usamos o conjunto de dados FashionMNIST. \n",
    "Cada `Dataset` TorchVision, inclui dois argumentos: `transform` e `target_transform` \n",
    "para modificar as amostras e os rótulos, respectivamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passamos o `Dataset` como argumento para `DataLoader`. Isso envolve um iterável sobre nosso conjunto de dados e suporta processamento em lote, amostragem, embaralhamento e carregamento de dados multiprocesso automáticos. Aqui, definimos um tamanho de lote de 64, ou seja, cada elemento no iterável do carregador de dados retornará um lote de 64 recursos e rótulos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leia mais sobre como [carregar dados no PyTorch](https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando Modelos\n",
    "===============\n",
    "\n",
    "Para definir uma rede neural no PyTorch, criamos uma classe que herda de \n",
    "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
    "Definimos as camadas da rede na função `__init__` e\n",
    "especificamos como os dados passarão pela rede na função `forward`.\n",
    "Para acelerar as operações na rede neural, movemos a rede para um\n",
    "[acelerador](https://pytorch.org/docs/stable/torch.html#accelerators)\n",
    "como CUDA, MPS, MTIA ou XPU. Se o acelerador atual estiver disponível, \n",
    "o utilizaremos. Caso contrário, utilizaremos a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Pytourch Acceleration only available in version 2.9 and above\n",
    "#device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "device = \"cuda\" if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leia mais sobre como [construir redes neurais no PyTorch ](https://docs.pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otimizando os Parâmetros do Modelo\n",
    "===============================\n",
    "\n",
    "Para treinar um modelo, precisamos de uma \n",
    "[função de perda](https://pytorch.org/docs/stable/nn.html#loss-functions) e um\n",
    "[otimizador](https://pytorch.org/docs/stable/optim.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em um único loop de treinamento, o modelo faz previsões no conjunto de dados de treinamento (alimentados em lotes) e retropropaga o erro de previsão para ajustar os parâmetros do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também verificamos o desempenho do modelo em relação ao conjunto de dados de teste para garantir que ele esteja aprendendo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo de treinamento é conduzido ao longo de várias iterações ( épocas ). Durante cada época, o modelo aprende parâmetros para fazer previsões melhores. Imprimimos a precisão e a perda do modelo em cada época; gostaríamos de ver a precisão aumentar e a perda diminuir a cada época.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  lr: 0.010000\n",
      "-------------------------------\n",
      "loss: 2.302054  [   64/60000]\n",
      "loss: 2.176207  [ 6464/60000]\n",
      "loss: 1.829522  [12864/60000]\n",
      "loss: 1.531255  [19264/60000]\n",
      "loss: 1.182514  [25664/60000]\n",
      "loss: 1.066007  [32064/60000]\n",
      "loss: 1.025747  [38464/60000]\n",
      "loss: 0.894046  [44864/60000]\n",
      "loss: 0.884338  [51264/60000]\n",
      "loss: 0.825370  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 0.807688 \n",
      "\n",
      "Epoch 2  lr: 0.010000\n",
      "-------------------------------\n",
      "loss: 0.821015  [   64/60000]\n",
      "loss: 0.865529  [ 6464/60000]\n",
      "loss: 0.619153  [12864/60000]\n",
      "loss: 0.791547  [19264/60000]\n",
      "loss: 0.673112  [25664/60000]\n",
      "loss: 0.639332  [32064/60000]\n",
      "loss: 0.725154  [38464/60000]\n",
      "loss: 0.700757  [44864/60000]\n",
      "loss: 0.699975  [51264/60000]\n",
      "loss: 0.645399  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.643260 \n",
      "\n",
      "Epoch 3  lr: 0.010000\n",
      "-------------------------------\n",
      "loss: 0.578585  [   64/60000]\n",
      "loss: 0.668642  [ 6464/60000]\n",
      "loss: 0.460061  [12864/60000]\n",
      "loss: 0.668476  [19264/60000]\n",
      "loss: 0.586748  [25664/60000]\n",
      "loss: 0.551150  [32064/60000]\n",
      "loss: 0.609290  [38464/60000]\n",
      "loss: 0.640191  [44864/60000]\n",
      "loss: 0.659534  [51264/60000]\n",
      "loss: 0.553464  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.577513 \n",
      "\n",
      "Epoch 4  lr: 0.010000\n",
      "-------------------------------\n",
      "loss: 0.484073  [   64/60000]\n",
      "loss: 0.574724  [ 6464/60000]\n",
      "loss: 0.396695  [12864/60000]\n",
      "loss: 0.595805  [19264/60000]\n",
      "loss: 0.533192  [25664/60000]\n",
      "loss: 0.508245  [32064/60000]\n",
      "loss: 0.553462  [38464/60000]\n",
      "loss: 0.632997  [44864/60000]\n",
      "loss: 0.642389  [51264/60000]\n",
      "loss: 0.491625  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.545076 \n",
      "\n",
      "Epoch 5  lr: 0.010000\n",
      "-------------------------------\n",
      "loss: 0.429673  [   64/60000]\n",
      "loss: 0.528636  [ 6464/60000]\n",
      "loss: 0.362747  [12864/60000]\n",
      "loss: 0.549748  [19264/60000]\n",
      "loss: 0.494606  [25664/60000]\n",
      "loss: 0.479550  [32064/60000]\n",
      "loss: 0.520450  [38464/60000]\n",
      "loss: 0.628798  [44864/60000]\n",
      "loss: 0.622843  [51264/60000]\n",
      "loss: 0.454369  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.523909 \n",
      "\n",
      "Epoch 6  lr: 0.010000\n",
      "-------------------------------\n",
      "loss: 0.390106  [   64/60000]\n",
      "loss: 0.502498  [ 6464/60000]\n",
      "loss: 0.339440  [12864/60000]\n",
      "loss: 0.520510  [19264/60000]\n",
      "loss: 0.468358  [25664/60000]\n",
      "loss: 0.460108  [32064/60000]\n",
      "loss: 0.496656  [38464/60000]\n",
      "loss: 0.617573  [44864/60000]\n",
      "loss: 0.604385  [51264/60000]\n",
      "loss: 0.433775  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.508510 \n",
      "\n",
      "Epoch 7  lr: 0.001000\n",
      "-------------------------------\n",
      "loss: 0.358932  [   64/60000]\n",
      "loss: 0.488762  [ 6464/60000]\n",
      "loss: 0.312554  [12864/60000]\n",
      "loss: 0.504772  [19264/60000]\n",
      "loss: 0.452364  [25664/60000]\n",
      "loss: 0.445876  [32064/60000]\n",
      "loss: 0.472366  [38464/60000]\n",
      "loss: 0.633695  [44864/60000]\n",
      "loss: 0.583226  [51264/60000]\n",
      "loss: 0.423867  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.476304 \n",
      "\n",
      "Epoch 8  lr: 0.001000\n",
      "-------------------------------\n",
      "loss: 0.342421  [   64/60000]\n",
      "loss: 0.484846  [ 6464/60000]\n",
      "loss: 0.308987  [12864/60000]\n",
      "loss: 0.502780  [19264/60000]\n",
      "loss: 0.448430  [25664/60000]\n",
      "loss: 0.443326  [32064/60000]\n",
      "loss: 0.469860  [38464/60000]\n",
      "loss: 0.633066  [44864/60000]\n",
      "loss: 0.582388  [51264/60000]\n",
      "loss: 0.421635  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.474797 \n",
      "\n",
      "Epoch 9  lr: 0.001000\n",
      "-------------------------------\n",
      "loss: 0.339946  [   64/60000]\n",
      "loss: 0.482704  [ 6464/60000]\n",
      "loss: 0.306867  [12864/60000]\n",
      "loss: 0.500884  [19264/60000]\n",
      "loss: 0.445180  [25664/60000]\n",
      "loss: 0.441024  [32064/60000]\n",
      "loss: 0.467465  [38464/60000]\n",
      "loss: 0.632025  [44864/60000]\n",
      "loss: 0.581349  [51264/60000]\n",
      "loss: 0.419759  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.473374 \n",
      "\n",
      "Epoch 10  lr: 0.001000\n",
      "-------------------------------\n",
      "loss: 0.337528  [   64/60000]\n",
      "loss: 0.480919  [ 6464/60000]\n",
      "loss: 0.304959  [12864/60000]\n",
      "loss: 0.499021  [19264/60000]\n",
      "loss: 0.442354  [25664/60000]\n",
      "loss: 0.438989  [32064/60000]\n",
      "loss: 0.465199  [38464/60000]\n",
      "loss: 0.630771  [44864/60000]\n",
      "loss: 0.580141  [51264/60000]\n",
      "loss: 0.418099  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.472010 \n",
      "\n",
      "Epoch 11  lr: 0.001000\n",
      "-------------------------------\n",
      "loss: 0.335135  [   64/60000]\n",
      "loss: 0.479233  [ 6464/60000]\n",
      "loss: 0.303165  [12864/60000]\n",
      "loss: 0.497252  [19264/60000]\n",
      "loss: 0.439657  [25664/60000]\n",
      "loss: 0.437126  [32064/60000]\n",
      "loss: 0.463088  [38464/60000]\n",
      "loss: 0.629416  [44864/60000]\n",
      "loss: 0.578838  [51264/60000]\n",
      "loss: 0.416546  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.470699 \n",
      "\n",
      "Epoch 12  lr: 0.001000\n",
      "-------------------------------\n",
      "loss: 0.332767  [   64/60000]\n",
      "loss: 0.477560  [ 6464/60000]\n",
      "loss: 0.301479  [12864/60000]\n",
      "loss: 0.495526  [19264/60000]\n",
      "loss: 0.437086  [25664/60000]\n",
      "loss: 0.435378  [32064/60000]\n",
      "loss: 0.461080  [38464/60000]\n",
      "loss: 0.628014  [44864/60000]\n",
      "loss: 0.577445  [51264/60000]\n",
      "loss: 0.415123  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.469425 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 12\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n",
    "for t in range(epochs):\n",
    "    lr_actual = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {t+1}  lr: {lr_actual:>7f}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "    scheduler.step()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leia mais sobre [Treinamento do seu modelo](https://docs.pytorch.org/tutorials/beginner/basics/optimization_tutorial.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando Modelos\n",
    "=============\n",
    "\n",
    "Uma maneira comum de salvar um modelo é serializar o dicionário de estado interno (contendo os parâmetros do modelo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando modelos\n",
    "==============\n",
    "\n",
    "O processo de carregamento de um modelo inclui recriar a estrutura do modelo e carregar o dicionário de estado nele.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo agora pode ser usado para fazer previsões.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in random.sample(range(101, 200), 1):\n",
    "        x, y = test_data[i][0], test_data[i][1]\n",
    "\n",
    "        x = x.to(device)\n",
    "        pred = model(x)\n",
    "        predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "\n",
    "        imagem_np = x.squeeze().cpu().numpy()\n",
    "        plt.imshow(imagem_np, cmap=\"gray\")\n",
    "        plt.title(f'id: {i} - Img: {classes[y]} > Prev: {predicted}')\n",
    "        plt.show()  \n",
    "\n",
    "        #print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leia mais sobre [como salvar e carregar seu modelo](https://docs.pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
